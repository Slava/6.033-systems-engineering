# Fault-tolerance - pessimistic replication

Requires strong consistency:

- Lock server
- Coordinator for 2PC


A way to do it:

- avoid inconsistencies
- trade-off availability

## Single-copy semantics

Externally the system is visible as if there is only one copy of data.

A naive solution is to have several servers and clients writing to all servers
every time. If a server fails, it can recover by replicating some other server
and continue accepting the client requests.

But this breaks if there is a network partitioning, some clients will talk to
server A and think that server B is down. And other clients will see only server
B and think A is down, thus achieving an inconsistent state. (same problem as
optimistic replication).

### Network partitions

Client cannot distinguish network failure vs server being down.

### Majority of servers

2/3 or 3/5 is a majority. Any two majorities must overlap. So if a client can
talk to a majority of servers, we allow execution.

## Replicated state machine (RSM)

- start in same state
- same input to each replica (same data, same order, etc)
- every operation is deterministic (no random-based behavior, no time-based
  behavior or anything else relying on the environment)

A naive solution for ordering: have a coordinator that will serialize
operations. A problem is - coordinator becomes a single point of failure.

And when does coordinator acknowledge the success to write? If we wait only to
one successful write, we can risk failing on that one machine. The system will
go on executing, as the majority is still available but the only machine with
that acknowledged operation is gone. The solution is to wait for a majority of
writes to complete - because if some servers fail but the majority survives,
this majority will overlap with the write majority. (someone will know about
that write)

How to get rid of the single coordinator. Let's have the coordinator to be one
of the replica set.

## Paxos: fault-tolerant consensus

Paxos is a protocol that provides these guarantees:

- all nodes agree on the same value
- should finish with less than N/2 failures (majority alive)
- may take long time (no guarantees to be fast in an unreliable environment, not
  important in practice)
- all nodes are fail-stop (doesn't guard from arbitrary software failures,
  guards from machine failures or network partitioning)

Proposers and Acceptors. One proposer and one acceptor per machine.

Proposers do or do not propose an operation for replica set to agree on.

Acceptors are voting on what proposal wins.

A simple solution is to have only one acceptor that just accepts only first
proposal. But then the only acceptor becomes a single point of failure.

Let's have several acceptors voting for some proposals. The proposal that gets
the majority of votes wins. This doesn't guarantee that some proposal has a
majority.

Have proposal numbers (or rounds of proposals). Each round superseeds the next
round if no consensus was reached. Each acceptor has the number of proposal it
agreed on, the number of proposal it accepted, number of proposal it last
accepted.

--- a lot of paxos stuff ---

Paxos relies on the fact that majorities overlap. In reality Paxos is quite
expensive and in reality a Paxos service is used to agree on the current
coordinator or a master for a time being to delegate all decisions to it.

