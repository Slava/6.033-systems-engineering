Logging
===

Setting. You have a single computer. You have a persistent storage. You need
a recovery mechanism using storage.

One of the ways to impleent transactions is "All-or-nothing" using shadow
copy. Using transactions users don't need to care about failures and
concurrency.

Shadow copy doesn't work that well because:
- you have only one file
- copying is expensive

Example:

    begin
      A<-100
      B<-50
    end
    begin
      A<-A-20
      B<-B+20
    end
    begin
      A<-A+30
      crash!

Simple scheme: log
---

Instead of shadow copies we write a log to disk. Logs are append-only.

Log example:

    T1 - A<-100
    T1 - B<-50
    T1 - commit
    T2 - A: 100->80
    T2 - B: 50->70
    T2 - commit
    T3 - A: 80->110

The idea is to have a good idea how to reconstruct the state from log
starting on the clean state. Every transaction that has a commit, becomes
visible/valid.

Reads work just by replaying log for every read.

Every log append should be an atomic operation. It can be achieved by
making every commit log a single disk block.

For aborted transactions we just don't write a commit log.

For recovery we don't need to do anything, we still can answer reads
replaying logs.


WAL: log + cell
---

(WAL: Write ahead log).

We add a second storage for the actual state that we call "cell". Now reads are
faster as we don't replay logs.

Now when we update a value, we have two steps: logging (writing a log) and
installing (updating cell).

How do we recover? What if we crash after logging and after updating cell but
before the commit? Our cell becomes out of date, on recovery we need to
repair it reverting log messages backwards till the correct point (roll
back).

It is important to write log first, before the updating cell, as we risk
losing the only copy - Write Ahead Logging.

We need to write an explicit "abort" log now. Important because we can
accidentally revert an aborted transaction, even though it wasn't applied.

How do we recover if we crashed during recovery? We can log every revert as an
"aborted" transaction during the recovery. But aborting something more than once
is fine if reverting is idempotent.

Now writes are slower (two writes instead of one) but reads are faster.

Redo/undo: log+cell+cache
---

To optimize writes, we can first write to cache and then flush the cache on
commit.

Reads also go to cache first. Here is some complexity with cache overflows:
should be careful not to flush uncommitted transactions.

Possible problems:
- missing changes (if we crashed before flushing or after
flushing to log but before flushing to cell disk).
- changes on cell disk we should not undo (or redo the undo)?

This makes the recovery much more complicated. Now we need to go over log
twice, second time going forward on log redoing undone changes. This will
guarantee that we never miss changes and never undo changes that we should do.
(called undo losers and redo winners).

Now reads and writes are OK, recovery is complicated but is worth it. The only
problem is a giant log.


Truncate logs
---

- Wait for no transactions (or stop accepting transactions)
- Flush cache (cell contains latest state now)
- Log a checkpoint record
- Once the checkpoint is written, we can truncate log

Good databases can take checkpoints while proceeding with transactions by
storing more information in checkpoint records.


Hands-on
===

Q1. Because transaction 2 hasn't been committed yet.

Q2. "studentA" with 900 and "studentC" with 3100.

Q3. Because we didn't "end" the transaction 3 that flushes to cell.

Q4. studentA with 900 and studentC with 3100.

Q5. Yes it matches. Because the finished transactions are not affected.

Q6. Losers: started but not committed. Winners: started, committed but not
finished. Done: started and finished.

Q7. Because transaction 2 has never committed or finished, checkpoint
describes it as PENDING and rightly so.

Q8. Only 6 lines were rolled back. The advantage of checkpoints is a
reduced space spent on logs and a faster recovery.

Q9. Yes, idempotence.

Q10. During the recovery we "finish" the winner transactions. That
preserves idempotence as the end data is the same and we always complete
winner transactions.

